# Agentic RAG using LlamaIndex

This project demonstrates a simple Retrieval-Augmented Generation (RAG) agent using LlamaIndex.

## Features
- Load documents
- Create vector index
- Ask questions over the data

## Tech Stack
- Python
- LlamaIndex
- OpenAI or local LLM

## How it Works
1. Documents are loaded from a folder.
2. They are converted into embeddings.
3. A vector index is created.
4. User queries are answered using relevant documents.

## Run the Project
```bash
pip install -r requirements.txt
python app.py
